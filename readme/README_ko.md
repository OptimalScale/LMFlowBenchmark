<p align="center" width="100%">
<img src="../assets/logo.png" alt="LMFlow" style="width: 100%; min-width: 300px; display: block; margin: auto; background-color: transparent;">
</p>

# LMFlow

<h4 align="center">
    <p>
        <a href="https://github.com/OptimalScale/LMFlow/blob/main/README.md">English</a> |
        <a href="https://github.com/OptimalScale/LMFlow/blob/main/readme/README_zh-hans.md">ç®€ä½“ä¸­æ–‡</a> |
        <a href="https://github.com/OptimalScale/LMFlow/blob/main/readme/README_es.md">EspaÃ±ol</a> |
        <a href="https://github.com/OptimalScale/LMFlow/blob/main/readme/README_jp.md">æ—¥æœ¬èª</a> |
        <b>í•œêµ­ì–´</b> |
        <a href="https://github.com/OptimalScale/LMFlow/blob/main/readme/README_hindi.md">à¤¹à¤¿à¤‚à¤¦à¥€</a>
    <p>
</h4>

í•œêµ­ì–´ ë²„ì „ì€ ChatGPTê°€ ë²ˆì—­í–ˆìŠµë‹ˆë‹¤. ì˜¤ë¥˜ê°€ ìˆìœ¼ë©´ contributorê°€ ìˆ˜ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê°ì‚¬í•©ë‹ˆë‹¤. ë˜í•œ, ì˜ì–´ ë²„ì „ê³¼ ë‚´ìš©ì´ ë‹¤ë¥¸ ë¶€ë¶„ì´ ìˆìœ¼ë©´ ì˜ì–´ ë²„ì „ì„ ë”°ë¥´ì‹­ì‹œì˜¤.

[![Code License](https://img.shields.io/badge/Code%20License-Apache_2.0-green.svg)](https://github.com/OptimalScale/LMFlow/blob/main/LICENSE)
[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/release/python-390/)
[![Doc](https://img.shields.io/badge/Website-Doc-ff69b4.svg)](https://optimalscale.github.io/LMFlow/)
[![Embark](https://img.shields.io/badge/discord-LMFlow-%237289da.svg?logo=discord)](https://discord.gg/u9VJNpzhvA)
[![slack badge](https://img.shields.io/badge/Slack-join-blueviolet?logo=slack&amp)](https://join.slack.com/t/lmflow/shared_invite/zt-1s6egx12s-THlwHuCjF6~JGKmx7JoJPA)
[![WeChat badge](https://img.shields.io/badge/WeChat-Join-brightgreen?logo=wechat&amp)](https://i.328888.xyz/2023/04/04/ibvpAk.jpeg)

This project provides a unified framework to evaluation generative large language models on different evaluation tasks.

ëª¨ë‘ë¥¼ ìœ„í•œ Large Language Model. See our [vision](https://github.com/OptimalScale/LMFlow#vision).

<p align="center" width="100%">
<img src="../assets/features.png" alt="LMFlow-features" style="width: 100%; min-width: 300px; display: block; margin: auto;">
</p>


## Latest News
* [2023-05-08] :rocket: Release [LMFlow Benchmark](https://medium.com/@hkust.ml/lmflow-benchmark-an-automatic-evaluation-framework-for-open-source-llms-ef5c6f142418), an automatic evaluation framework for open-source chat-style LLMs. [Benchmark results](https://docs.google.com/spreadsheets/d/1JYh4_pxNzmNA9I0YM2epgRA7VXBIeIGS64gPJBg5NHA/edit#gid=0) on 31 popular models are reported. [Participate in LMFlow Benchmark](https://github.com/OptimalScale/LMFlow#33-lmflow-benchmark). :rocket:


## Supported Models

ğŸ¤— huggingfaceì˜ ëª¨ë“  [ë””ì½”ë” ëª¨ë¸](https://huggingface.co/models?pipeline_tag=text-generation&sort=downloads) ì„ ì›í™œí•˜ê²Œ ì§€ì›í•©ë‹ˆë‹¤. LLaMA, GPT2, GPT-Neo, Galactica ë“±ì€ ì™„ì „íˆ í…ŒìŠ¤íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤. ìš°ë¦¬ëŠ” ê³§ ì¸ì½”ë” ëª¨ë¸ë„ ì§€ì›í•  ì˜ˆì •ì…ë‹ˆë‹¤.


## 1.Setup

ì†Œí”„íŠ¸ì›¨ì–´ íŒ¨í‚¤ì§€ëŠ” Linux ìš´ì˜ ì²´ì œ(Ubuntu 20.04)ì—ì„œ ì™„ì „íˆ í…ŒìŠ¤íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ìš´ì˜ ì²´ì œ í”Œë«í¼(MacOS, Windows)ì€ ì•„ì§ ì™„ì „íˆ í…ŒìŠ¤íŠ¸ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.
ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ê°€ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.Linux ì‹œìŠ¤í…œì—ì„œ ë¨¼ì € ì‹œë„í•˜ê±°ë‚˜ Google Colabì„ ì‚¬ìš©í•˜ì—¬ ê²½í—˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```bash
git clone https://github.com/OptimalScale/LMFlow.git
cd LMFlow
conda create -n lmflow python=3.9 -y
conda activate lmflow
conda install mpi4py
pip install -e .
```

## 2.Prepare Dataset

Please refer to our [doc](https://optimalscale.github.io/LMFlow/examples/DATASETS.html).

## 3. Running Scripts
### 3.1 LMFlow Benchmark
LMFlow Benchmark is an automatic evaluation framework for open-source large language models.
We use negative log likelihood (NLL) as the metric to evaluate different aspects of a language model: chitchat, commonsense reasoning, and instruction following abilities.

You can directly run the LMFlow benchmark evaluation to obtain the results to participate in the
[LLM comparision](https://docs.google.com/spreadsheets/d/1JYh4_pxNzmNA9I0YM2epgRA7VXBIeIGS64gPJBg5NHA/edit?usp=sharing).
For example, to run GPT2 XL, one may execute
```sh
./scripts/run_benchmark.sh --model_name_or_path gpt2-xl
```
`--model_name_or_path` is required, you may fill in huggingface model name or local model path here.

To check the evaluation results, you may check `benchmark.log` in `./output_dir/gpt2-xl_lmflow_chat_nll_eval`,
`./output_dir/gpt2-xl_all_nll_eval` and `./output_dir/gpt2-xl_commonsense_qa_eval`.


## Vision
ì•ˆë…•í•˜ì„¸ìš”! ìš°ë¦¬ëŠ” ì™„ì „í•œ LLM í•™ìŠµ í”„ë¡œì„¸ìŠ¤ë¥¼ í¬í•¨í•˜ì—¬ ì‚¬ìš©ìê°€ ìì‹ ì˜ ì–¸ì–´ ëª¨ë¸ì„ ë¹ ë¥´ê²Œ êµ¬ì¶•í•˜ê³  íš¨ê³¼ì ìœ¼ë¡œ í•™ìŠµ í•  ìˆ˜ ìˆë„ë¡í•˜ëŠ” ì½”ë“œ repositoryê°€ ê³§ ì¶œì‹œ ë  ê²ƒì„ ë°œí‘œí•˜ê²Œ ë˜ì–´ ê¸°ì©ë‹ˆë‹¤.

ìš°ë¦¬ì˜ ì½”ë“œ repositoryëŠ” ë‹¨ìˆœí•œ ëª¨ë¸ì´ ì•„ë‹ˆë©° ì™„ì „í•œ í•™ìŠµ ì›Œí¬ í”Œë¡œ, ëª¨ë¸ ìµœì í™” ë° í…ŒìŠ¤íŠ¸ ë„êµ¬ë¥¼ í¬í•¨í•©ë‹ˆë‹¤. ëŒ€í™” ëª¨ë¸, ì§ˆë¬¸-ë‹µë³€ ëª¨ë¸ ë° ê¸°íƒ€ í…ìŠ¤íŠ¸ ìƒì„± ëª¨ë¸ì„ ë¹„ë¡¯í•œ ë‹¤ì–‘í•œ ìœ í˜•ì˜ ì–¸ì–´ ëª¨ë¸ì„ êµ¬ì¶•í•˜ëŠ” ë° ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ë˜í•œ ìš°ë¦¬ëŠ” LLM ê³µìœ  í”Œë«í¼ì„ ë§Œë“¤ì–´ ì‚¬ëŒë“¤ì´ ì²´í¬í¬ì¸íŠ¸ì™€ ê²½í—˜ì„ ê³µìœ í•˜ì—¬ ì»¤ë®¤ë‹ˆí‹°ì˜ ê¸°ìˆ ì„ í•¨ê»˜ ê°œì„ í•  ìˆ˜ ìˆëŠ” ê°œë°©ì ì´ê³  ë¯¼ì£¼ì ì¸ LLM ê³µìœ  í”Œë«í¼ì„ ë§Œë“¤ê³ ìí•©ë‹ˆë‹¤. LLMì— ê´€ì‹¬ìˆëŠ” ëˆ„êµ¬ë‚˜ ì°¸ì—¬í•˜ì—¬ ì¹œê·¼í•˜ê³  ê°œë°©ì ì¸ ì»¤ë®¤ë‹ˆí‹°ë¥¼ ë§Œë“¤ì–´ ê°€ëŠ” ê²ƒì„ í™˜ì˜í•©ë‹ˆë‹¤!

ì´ˆë³´ìë“  ì „ë¬¸ê°€ë“  ìƒê´€ì—†ì´ ì´ í”Œë«í¼ì—ì„œ í˜œíƒì„ ë°›ì„ ìˆ˜ ìˆì„ ê²ƒì´ë¼ê³  ë¯¿ìŠµë‹ˆë‹¤. í•¨ê»˜ í™œê¸°ì°¨ê³  í˜ì‹ ì ì¸ LLM ì»¤ë®¤ë‹ˆí‹°ë¥¼ ë§Œë“¤ì–´ ë´…ì‹œë‹¤!

[![Embark](https://img.shields.io/badge/discord-LMFlow-%237289da.svg?logo=discord)](https://discord.gg/u9VJNpzhvA)
[![slack badge](https://img.shields.io/badge/Slack-join-blueviolet?logo=slack&amp)](https://join.slack.com/t/lmflow/shared_invite/zt-1s6egx12s-THlwHuCjF6~JGKmx7JoJPA)
[![WeChat badge](https://img.shields.io/badge/WeChat-Join-brightgreen?logo=wechat&amp)](https://i.328888.xyz/2023/04/04/ibvpAk.jpeg)


## Support

ë„ì›€ì´ í•„ìš”í•˜ë©´ [Github](https://github.com/OptimalScale/LMFlow)ì— ë¬¸ì œë¥¼ ì œì¶œí•˜ì‹­ì‹œì˜¤.

## Contributors
<a href="https://github.com/OptimalScale/LMFlow/graphs/contributors">
  <img src="https://contrib.rocks/image?repo=OptimalScale/LMFlow" />
</a>

## Citation
ì´ repositoryë¥¼ ìœ ìš©í•˜ê²Œ ì‚¬ìš©í•˜ì…¨ë‹¤ë©´ â­ì„ ëˆŒëŸ¬ì£¼ì‹œê³  citeí•´ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤:

```
@misc{lmflow,
  author = {Shizhe Diao and Rui Pan and Hanze Dong and KaShun Shum and Jipeng Zhang and Wei Xiong and Tong Zhang},
  title = {LMFlow: An Extensible Toolkit for Finetuning and Inference of Large Foundation Models},
  year = {2023},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://optimalscale.github.io/LMFlow/}},
}
```
