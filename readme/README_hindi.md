<p align="center" width="100%">
<img src="../assets/logo.png" alt="LMFlow" style="width: 100%; min-width: 300px; display: block; margin: auto; background-color: transparent;">
</p>

# LMFlow

<h4 align="center">
    <p>
        <a href="https://github.com/OptimalScale/LMFlow/blob/main/README.md">English</a> |
        <a href="https://github.com/OptimalScale/LMFlow/blob/main/readme/README_zh-hans.md">ÁÆÄ‰Ωì‰∏≠Êñá</a> |
        <a href="https://github.com/OptimalScale/LMFlow/blob/main/readme/README_es.md">Espa√±ol</a> |
        <a href="https://github.com/OptimalScale/LMFlow/blob/main/readme/README_jp.md">Êó•Êú¨Ë™û</a> |
        <a href="https://github.com/OptimalScale/LMFlow/blob/main/readme/README_ko.md">ÌïúÍµ≠Ïñ¥</a> |
        <b>‡§π‡§ø‡§Ç‡§¶‡•Ä</b>
    <p>
</h4>

‡§Ø‡§π ‡§ö‡•à‡§ü‡§ú‡•Ä‡§™‡•Ä‡§ü‡•Ä ‡§¶‡•ç‡§µ‡§æ‡§∞‡§æ ‡§Ö‡§®‡•Å‡§µ‡§æ‡§¶‡§ø‡§§ ‡§π‡§ø‡§Ç‡§¶‡•Ä ‡§∏‡§Ç‡§∏‡•ç‡§ï‡§∞‡§£ ‡§π‡•à, ‡§Ø‡§¶‡§ø ‡§ï‡•ã‡§à ‡§§‡•ç‡§∞‡•Å‡§ü‡§ø ‡§π‡•ã, ‡§§‡•ã ‡§∏‡§Ç‡§¨‡§Ç‡§ß‡§ø‡§§ ‡§Ø‡•ã‡§ó‡§¶‡§æ‡§®‡§ï‡§∞‡•ç‡§§‡§æ‡§ì‡§Ç ‡§¶‡•ç‡§µ‡§æ‡§∞‡§æ ‡§∏‡§Ç‡§∂‡•ã‡§ß‡§ø‡§§ ‡§ï‡§ø‡§Ø‡§æ ‡§ú‡§æ ‡§∏‡§ï‡§§‡§æ ‡§π‡•à‡•§ ‡§á‡§∏‡§ï‡•á ‡§∏‡§æ‡§• ‡§π‡•Ä ‡§Ø‡§¶‡§ø ‡§ï‡•ã‡§à ‡§∏‡§æ‡§Æ‡§ó‡•ç‡§∞‡•Ä ‡§Ö‡§Ç‡§ó‡•ç‡§∞‡•á‡§ú‡•Ä ‡§∏‡§Ç‡§∏‡•ç‡§ï‡§∞‡§£ ‡§∏‡•á ‡§≠‡§ø‡§®‡•ç‡§® ‡§π‡•ã ‡§Ø‡§æ ‡§Æ‡•á‡§≤ ‡§®‡§π‡•Ä‡§Ç ‡§ñ‡§æ‡§§‡•Ä ‡§π‡•ã, ‡§§‡•ã ‡§ï‡•É‡§™‡§Ø‡§æ ‡§Ö‡§Ç‡§ó‡•ç‡§∞‡•á‡§ú‡•Ä ‡§∏‡§Ç‡§∏‡•ç‡§ï‡§∞‡§£ ‡§ï‡•ã ‡§π‡•Ä ‡§Æ‡§æ‡§®‡•ç‡§Ø ‡§∞‡§ñ‡•á‡§Ç‡•§ ‡§ß‡§®‡•ç‡§Ø‡§µ‡§æ‡§¶‡•§

[![Code License](https://img.shields.io/badge/Code%20License-Apache_2.0-green.svg)](https://github.com/OptimalScale/LMFlow/blob/main/LICENSE)
[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/release/python-390/)
[![Doc](https://img.shields.io/badge/Website-Doc-ff69b4.svg)](https://optimalscale.github.io/LMFlow/)
[![Embark](https://img.shields.io/badge/discord-LMFlow-%237289da.svg?logo=discord)](https://discord.gg/u9VJNpzhvA)
[![slack badge](https://img.shields.io/badge/Slack-join-blueviolet?logo=slack&amp)](https://join.slack.com/t/lmflow/shared_invite/zt-1s6egx12s-THlwHuCjF6~JGKmx7JoJPA)
[![WeChat badge](https://img.shields.io/badge/WeChat-Join-brightgreen?logo=wechat&amp)](https://i.328888.xyz/2023/04/04/ibvpAk.jpeg)

This project provides a unified framework to evaluation generative large language models on different evaluation tasks.‡•§

‡§≤‡§æ‡§∞‡•ç‡§ú ‡§≤‡•à‡§Ç‡§ó‡•ç‡§µ‡•á‡§ú ‡§Æ‡•â‡§°‡§≤ ‡§´‡•â‡§∞ ‡§ë‡§≤‡•§ ‡§π‡§Æ‡§æ‡§∞‡•Ä [‡§¶‡•É‡§∑‡•ç‡§ü‡§ø](https://github.com/OptimalScale/LMFlow#vision) ‡§¶‡•á‡§ñ‡•á‡§Ç‡•§

<p align="center" width="100%">
<img src="../assets/features.png" alt="LMFlow-features" style="width: 100%; min-width: 300px; display: block; margin: auto;">
</p>


## Latest News
* [2023-05-08] :rocket: Release [LMFlow Benchmark](https://medium.com/@hkust.ml/lmflow-benchmark-an-automatic-evaluation-framework-for-open-source-llms-ef5c6f142418), an automatic evaluation framework for open-source chat-style LLMs. [Benchmark results](https://docs.google.com/spreadsheets/d/1JYh4_pxNzmNA9I0YM2epgRA7VXBIeIGS64gPJBg5NHA/edit#gid=0) on 31 popular models are reported. [Participate in LMFlow Benchmark](https://github.com/OptimalScale/LMFlow#33-lmflow-benchmark). :rocket:



## Supported Models
ü§ó huggingface ‡§Æ‡•á‡§Ç ‡§∏‡§≠‡•Ä [decoder models](https://huggingface.co/models?pipeline_tag=text-generation&sort=downloads) ‡§ï‡§æ ‡§∏‡§π‡§ú ‡§§‡§∞‡•Ä‡§ï‡•á ‡§∏‡•á ‡§∏‡§Æ‡§∞‡•ç‡§•‡§® ‡§ï‡§ø‡§Ø‡§æ ‡§ó‡§Ø‡§æ ‡§π‡•à‡•§
LLaMA, GPT2, GPT-Neo, Galactica, ‡§ï‡•ã ‡§™‡•Ç‡§∞‡•Ä ‡§§‡§∞‡§π ‡§∏‡•á ‡§ü‡•á‡§∏‡•ç‡§ü ‡§ï‡§ø‡§Ø‡§æ ‡§ó‡§Ø‡§æ ‡§π‡•à‡•§ ‡§π‡§Æ ‡§ú‡§≤‡•ç‡§¶ ‡§π‡•Ä ‡§è‡§®‡§ï‡•ã‡§°‡§∞ ‡§Æ‡•â‡§°‡§≤ ‡§ï‡§æ ‡§∏‡§Æ‡§∞‡•ç‡§•‡§® ‡§ï‡§∞‡•á‡§Ç‡§ó‡•á‡•§

## 1.Setup

‡§π‡§Æ‡§æ‡§∞‡•Ä ‡§™‡•à‡§ï‡•á‡§ú‡§ø‡§Ç‡§ó ‡§≤‡§ø‡§®‡§ï‡•ç‡§∏ ‡§ì‡§è‡§∏ (‡§â‡§¨‡§Ç‡§ü‡•Ç 20.04) ‡§™‡§∞ ‡§™‡•Ç‡§∞‡•Ä ‡§§‡§∞‡§π ‡§∏‡•á ‡§ü‡•á‡§∏‡•ç‡§ü ‡§ï‡•Ä ‡§ó‡§à ‡§π‡•à‡•§ ‡§Ö‡§®‡•ç‡§Ø ‡§ì‡§è‡§∏ ‡§™‡•ç‡§≤‡•á‡§ü‡§´‡•â‡§∞‡•ç‡§Æ (MacOS, Windows) ‡§™‡•Ç‡§∞‡•Ä ‡§§‡§∞‡§π ‡§∏‡•á ‡§ü‡•á‡§∏‡•ç‡§ü ‡§®‡§π‡•Ä‡§Ç ‡§ï‡§ø‡§è ‡§ó‡§è ‡§π‡•à‡§Ç‡•§
‡§Ü‡§™ ‡§ï‡•Å‡§õ ‡§Ö‡§™‡•ç‡§∞‡§§‡•ç‡§Ø‡§æ‡§∂‡§ø‡§§ ‡§§‡•ç‡§∞‡•Å‡§ü‡§ø‡§Ø‡•ã‡§Ç ‡§∏‡•á ‡§Æ‡§ø‡§≤ ‡§∏‡§ï‡§§‡•á ‡§π‡•à‡§Ç. ‡§Ü‡§™ ‡§á‡§∏‡•á ‡§™‡§π‡§≤‡•á ‡§≤‡§ø‡§®‡§ï‡•ç‡§∏ ‡§Æ‡§∂‡•Ä‡§® ‡§™‡§∞ ‡§ï‡•ã‡§∂‡§ø‡§∂ ‡§ï‡§∞ ‡§∏‡§ï‡§§‡•á ‡§π‡•à‡§Ç ‡§Ø‡§æ ‡§á‡§∏‡•á ‡§Ö‡§®‡•Å‡§≠‡§µ ‡§ï‡§∞‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§ó‡•Ç‡§ó‡§≤ ‡§ï‡•ã‡§≤‡•á‡§¨ ‡§á‡§∏‡•ç‡§§‡•á‡§Æ‡§æ‡§≤ ‡§ï‡§∞ ‡§∏‡§ï‡§§‡•á ‡§π‡•à‡§Ç.

```bash
git clone https://github.com/OptimalScale/LMFlow.git
cd LMFlow
conda create -n lmflow python=3.9 -y
conda activate lmflow
conda install mpi4py
pip install -e .
```

## 2.Prepare Dataset

Please refer to our [doc](https://optimalscale.github.io/LMFlow/examples/DATASETS.html).

## 3. Running Scripts
### 3.1 LMFlow Benchmark
LMFlow Benchmark is an automatic evaluation framework for open-source large language models.
We use negative log likelihood (NLL) as the metric to evaluate different aspects of a language model: chitchat, commonsense reasoning, and instruction following abilities.

You can directly run the LMFlow benchmark evaluation to obtain the results to participate in the
[LLM comparision](https://docs.google.com/spreadsheets/d/1JYh4_pxNzmNA9I0YM2epgRA7VXBIeIGS64gPJBg5NHA/edit?usp=sharing).
For example, to run GPT2 XL, one may execute
```sh
./scripts/run_benchmark.sh --model_name_or_path gpt2-xl
```
`--model_name_or_path` is required, you may fill in huggingface model name or local model path here.

To check the evaluation results, you may check `benchmark.log` in `./output_dir/gpt2-xl_lmflow_chat_nll_eval`,
`./output_dir/gpt2-xl_all_nll_eval` and `./output_dir/gpt2-xl_commonsense_qa_eval`.

## Vision
‡§®‡§Æ‡§∏‡•ç‡§§‡•á! ‡§π‡§Æ ‡§Ü‡§™‡§ï‡•ã ‡§¨‡§§‡§æ‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§â‡§§‡•ç‡§∏‡§æ‡§π‡§ø‡§§ ‡§π‡•à‡§Ç ‡§ï‡§ø ‡§π‡§Æ‡§æ‡§∞‡•Ä ‡§ï‡•ã‡§° ‡§∞‡§ø‡§™‡•â‡§ú‡§ø‡§ü‡§∞‡•Ä ‡§ï‡•á ‡§Ü‡§ó‡§æ‡§Æ‡•Ä ‡§∞‡§ø‡§≤‡•Ä‡§ú ‡§ï‡•Ä ‡§ò‡•ã‡§∑‡§£‡§æ ‡§ï‡§∞‡§®‡•á ‡§ú‡§æ ‡§∞‡§π‡•á ‡§π‡•à‡§Ç, ‡§ú‡•ã ‡§è‡§ï ‡§™‡•Ç‡§∞‡•ç‡§£ LLM ‡§ü‡•ç‡§∞‡•á‡§®‡§ø‡§Ç‡§ó ‡§™‡•ç‡§∞‡§ï‡•ç‡§∞‡§ø‡§Ø‡§æ ‡§ï‡•ã ‡§∂‡§æ‡§Æ‡§ø‡§≤ ‡§ï‡§∞‡§§‡•Ä ‡§π‡•à, ‡§ú‡•ã ‡§â‡§™‡§Ø‡•ã‡§ó‡§ï‡§∞‡•ç‡§§‡§æ‡§ì‡§Ç ‡§ï‡•ã ‡§Ö‡§™‡§®‡•á ‡§ñ‡•Å‡§¶ ‡§ï‡•á ‡§≠‡§æ‡§∑‡§æ ‡§Æ‡•â‡§°‡§≤ ‡§§‡•à‡§Ø‡§æ‡§∞ ‡§ï‡§∞‡§®‡•á ‡§î‡§∞ ‡§â‡§®‡•ç‡§π‡•á‡§Ç ‡§™‡•ç‡§∞‡§≠‡§æ‡§µ‡•Ä ‡§¢‡§Ç‡§ó ‡§∏‡•á ‡§ü‡•ç‡§∞‡•á‡§® ‡§ï‡§∞‡§®‡•á ‡§ï‡•Ä ‡§Ö‡§®‡•Å‡§Æ‡§§‡§ø ‡§¶‡•á‡§§‡•Ä ‡§π‡•à‡•§

‡§π‡§Æ‡§æ‡§∞‡•Ä ‡§ï‡•ã‡§° ‡§∞‡§ø‡§™‡•â‡§ú‡§ø‡§ü‡§∞‡•Ä ‡§¨‡§∏ ‡§è‡§ï ‡§∏‡§æ‡§ß‡§æ‡§∞‡§£ ‡§Æ‡•â‡§°‡§≤ ‡§®‡§π‡•Ä‡§Ç ‡§π‡•à; ‡§á‡§∏‡§Æ‡•á‡§Ç ‡§™‡•Ç‡§∞‡•ç‡§£ ‡§ü‡•ç‡§∞‡•á‡§®‡§ø‡§Ç‡§ó ‡§µ‡§∞‡•ç‡§ï‡§´‡§º‡•ç‡§≤‡•ã, ‡§Æ‡•â‡§°‡§≤ ‡§ë‡§™‡•ç‡§ü‡§ø‡§Æ‡§æ‡§á‡§ú‡•á‡§∂‡§® ‡§î‡§∞ ‡§ü‡•á‡§∏‡•ç‡§ü‡§ø‡§Ç‡§ó ‡§ü‡•Ç‡§≤‡•ç‡§∏ ‡§∂‡§æ‡§Æ‡§ø‡§≤ ‡§π‡•à‡§Ç‡•§ ‡§Ü‡§™ ‡§á‡§∏‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§µ‡§ø‡§≠‡§ø‡§®‡•ç‡§® ‡§™‡•ç‡§∞‡§ï‡§æ‡§∞ ‡§ï‡•á ‡§≠‡§æ‡§∑‡§æ ‡§Æ‡•â‡§°‡§≤ ‡§§‡•à‡§Ø‡§æ‡§∞ ‡§ï‡§∞‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§ï‡§∞ ‡§∏‡§ï‡§§‡•á ‡§π‡•à‡§Ç, ‡§ú‡§ø‡§∏‡§Æ‡•á‡§Ç ‡§¨‡§æ‡§§‡§ö‡•Ä‡§§ ‡§Æ‡•â‡§°‡§≤, ‡§™‡•ç‡§∞‡§∂‡•ç‡§®-‡§â‡§§‡•ç‡§§‡§∞ ‡§Æ‡•â‡§°‡§≤ ‡§î‡§∞ ‡§ü‡•á‡§ï‡•ç‡§∏‡•ç‡§ü ‡§ú‡§®‡§∞‡•á‡§∂‡§® ‡§Æ‡•â‡§°‡§≤ ‡§Ü‡§¶‡§ø ‡§∂‡§æ‡§Æ‡§ø‡§≤ ‡§π‡•à‡§Ç‡•§

‡§á‡§∏‡§ï‡•á ‡§Ö‡§§‡§ø‡§∞‡§ø‡§ï‡•ç‡§§, ‡§π‡§Æ‡§æ‡§∞‡§æ ‡§≤‡§ï‡•ç‡§∑‡•ç‡§Ø ‡§è‡§ï ‡§ñ‡•Å‡§≤‡§æ ‡§î‡§∞ ‡§≤‡•ã‡§ï‡§§‡§æ‡§Ç‡§§‡•ç‡§∞‡§ø‡§ï LLM ‡§∏‡§æ‡§ù‡§æ ‡§ï‡§∞‡§®‡•á ‡§ï‡§æ ‡§Æ‡§Ç‡§ö ‡§¨‡§®‡§æ‡§®‡§æ ‡§π‡•à ‡§ú‡§π‡§æ‡§Ç ‡§≤‡•ã‡§ó ‡§Ö‡§™‡§®‡•á ‡§ö‡•á‡§ï‡§™‡•â‡§á‡§Ç‡§ü ‡§î‡§∞ ‡§Ö‡§®‡•Å‡§≠‡§µ ‡§∏‡§æ‡§ù‡§æ ‡§ï‡§∞‡§ï‡•á ‡§∏‡§Æ‡•Å‡§¶‡§æ‡§Ø ‡§ï‡•á ‡§ï‡•å‡§∂‡§≤‡•ã‡§Ç ‡§ï‡•ã ‡§∏‡§Ç‡§ó‡§†‡§ø‡§§ ‡§¢‡§Ç‡§ó ‡§∏‡•á ‡§∏‡•Å‡§ß‡§æ‡§∞ ‡§∏‡§ï‡§§‡•á ‡§π‡•à‡§Ç‡•§ ‡§π‡§Æ ‡§â‡§® ‡§∏‡§≠‡•Ä ‡§≤‡•ã‡§ó‡•ã‡§Ç ‡§ï‡§æ ‡§∏‡•ç‡§µ‡§æ‡§ó‡§§ ‡§ï‡§∞‡§§‡•á ‡§π‡•à‡§Ç ‡§ú‡•ã LLM ‡§Æ‡•á‡§Ç ‡§∞‡•Ç‡§ö‡§ø ‡§∞‡§ñ‡§§‡•á ‡§π‡•à‡§Ç ‡§î‡§∞ ‡§è‡§ï ‡§ñ‡•Å‡§≤‡•á ‡§î‡§∞ ‡§Æ‡§ø‡§§‡•ç‡§∞‡§µ‡§æ‡§π‡•Ä ‡§∏‡§Æ‡•Å‡§¶‡§æ‡§Ø ‡§ï‡§æ ‡§®‡§ø‡§∞‡•ç‡§Æ‡§æ‡§£ ‡§ï‡§∞‡§®‡•á ‡§Æ‡•á‡§Ç ‡§π‡§Æ‡§æ‡§∞‡•á ‡§∏‡§æ‡§• ‡§∂‡§æ‡§Æ‡§ø‡§≤ ‡§π‡•ã‡§®‡§æ ‡§ö‡§æ‡§π‡§§‡•á ‡§π‡•à‡§Ç!

‡§ö‡§æ‡§π‡•á ‡§Ü‡§™ ‡§è‡§ï ‡§∂‡•Å‡§∞‡•Å‡§Ü‡§§‡•Ä ‡§π‡•ã‡§Ç ‡§Ø‡§æ ‡§è‡§ï ‡§µ‡§ø‡§∂‡•á‡§∑‡§ú‡•ç‡§û, ‡§π‡§Æ ‡§Ø‡§π ‡§Æ‡§æ‡§®‡§§‡•á ‡§π‡•à‡§Ç ‡§ï‡§ø ‡§Ü‡§™ ‡§á‡§∏ ‡§Æ‡§Ç‡§ö ‡§∏‡•á ‡§≤‡§æ‡§≠ ‡§â‡§†‡§æ ‡§∏‡§ï‡§§‡•á ‡§π‡•à‡§Ç‡•§ ‡§Ü‡§ì ‡§π‡§Æ ‡§∏‡§æ‡§• ‡§Æ‡§ø‡§≤‡§ï‡§∞ ‡§è‡§ï ‡§ú‡•Ä‡§µ‡§Ç‡§§ ‡§î‡§∞ ‡§®‡§µ‡§æ‡§ö‡§æ‡§∞‡•Ä LLM ‡§∏‡§Æ‡•Å‡§¶‡§æ‡§Ø ‡§ï‡§æ ‡§®‡§ø‡§∞‡•ç‡§Æ‡§æ‡§£ ‡§ï‡§∞‡•á‡§Ç!
[![Embark](https://img.shields.io/badge/discord-LMFlow-%237289da.svg?logo=discord)](https://discord.gg/u9VJNpzhvA)
[![slack badge](https://img.shields.io/badge/Slack-join-blueviolet?logo=slack&amp)](https://join.slack.com/t/lmflow/shared_invite/zt-1s6egx12s-THlwHuCjF6~JGKmx7JoJPA)
[![WeChat badge](https://img.shields.io/badge/WeChat-Join-brightgreen?logo=wechat&amp)](https://i.328888.xyz/2023/04/04/ibvpAk.jpeg)


## Support
‡§Ø‡§¶‡§ø ‡§Ü‡§™‡§ï‡•ã ‡§ï‡§ø‡§∏‡•Ä ‡§≠‡•Ä ‡§Æ‡§¶‡§¶ ‡§ï‡•Ä ‡§Ü‡§µ‡§∂‡•ç‡§Ø‡§ï‡§§‡§æ ‡§π‡•ã ‡§§‡•ã, ‡§ï‡•É‡§™‡§Ø‡§æ ‡§è‡§ï [Github](https://github.com/OptimalScale/LMFlow) ‡§á‡§∂‡•Å ‡§™‡•ç‡§∞‡§∏‡•ç‡§§‡•Å‡§§ ‡§ï‡§∞‡•á‡§Ç‡•§
## Contributors
<a href="https://github.com/OptimalScale/LMFlow/graphs/contributors">
  <img src="https://contrib.rocks/image?repo=OptimalScale/LMFlow" />
</a>

## Citation
‡§Ø‡§¶‡§ø ‡§Ü‡§™‡§ï‡•ã ‡§Ø‡§π ‡§∞‡•á‡§™‡•ã ‡§â‡§™‡§Ø‡•ã‡§ó‡•Ä ‡§≤‡§ó‡§§‡§æ ‡§π‡•à, ‡§§‡•ã ‡§ï‡•É‡§™‡§Ø‡§æ ‚≠ê ‡§¶‡•á‡§®‡•á ‡§î‡§∞ ‡§â‡§¶‡•ç‡§ß‡§∞‡§£ ‡§ï‡§∞‡§®‡•á ‡§ï‡§æ ‡§µ‡§ø‡§ö‡§æ‡§∞ ‡§ï‡§∞‡•á‡§Ç:

```
@misc{lmflow,
  author = {Shizhe Diao and Rui Pan and Hanze Dong and KaShun Shum and Jipeng Zhang and Wei Xiong and Tong Zhang},
  title = {LMFlow: An Extensible Toolkit for Finetuning and Inference of Large Foundation Models},
  year = {2023},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://optimalscale.github.io/LMFlow/}},
}
```
